{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514b9aab",
   "metadata": {},
   "source": [
    "<img src=\"./ESSENCE.png\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4d7b7-40bf-43b9-a626-2a11d5529ac8",
   "metadata": {},
   "source": [
    "### Reflection pattern\n",
    "\n",
    "## input -> function(input) -> output -> function(output) -> output2\n",
    "\n",
    "<img src=\"./INPUT_OUTPUT.png\" width=700px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e847f",
   "metadata": {},
   "source": [
    "## Agent One is a code expert. Agent Two is an expert code reviewer.\n",
    "\n",
    "We generate a response with our first query using a system prompt to create code.\n",
    "\n",
    "We then pass the output into another function that acts as a reviewer to produce the next version of the code.\n",
    "\n",
    "This can be repeated until we reach certain criteria or MAX_ITERATIONS, whichever comes first.\n",
    "\n",
    "Each query is as if it was the first query with more information contained within it as each request is stateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96731d2f-a079-4e41-9756-220f02d4ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9737534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_client(llm_choice):\n",
    "    if llm_choice == \"GROQ\":\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "        )\n",
    "        return client\n",
    "    elif llm_choice == \"OPENAI\":\n",
    "        load_dotenv()  # load environment variables from .env fil\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        return client\n",
    "    else:\n",
    "        raise ValueError(\"Invalid LLM choice. Please choose 'GROQ' or 'OPENAI'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af18ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exists and begins sk-proj-1WUVgv...\n",
      "GROQ_API_KEY exists and begins gsk_11hFN1EMfj...\n",
      "LLM_CHOICE: OPENAI - MODEL: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "LLM_CHOICE = \"OPENAI\"\n",
    "# LLM_CHOICE = \"GROQ\"\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OPENAI_API_KEY exists and begins {OPENAI_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"GROQ_API_KEY exists and begins {GROQ_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY not set\")\n",
    "\n",
    "\n",
    "client = get_llm_client(LLM_CHOICE)\n",
    "if LLM_CHOICE == \"GROQ\":\n",
    "    MODEL = \"llama-3.3-70b-versatile\"\n",
    "else:\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"LLM_CHOICE: {LLM_CHOICE} - MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a635-e035-44e2-8c25-cee0f2b56556",
   "metadata": {},
   "source": [
    "We will start the **\"generation\"** chat history with the system prompt, as we said before. In this case, let the LLM act like a Python\n",
    "programmer eager to receive feedback / critique by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12467256-c741-495a-9923-439c1fcf270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "You are a Python programmer tasked with generating high quality Python code. Your task is to Generate the best content possible for the user's request. If the user requests critique, respond with a revised version of your previous attempt.\n",
    "\"\"\"\n",
    "\n",
    "generation_chat_history = [{\"role\": \"system\", \"content\": content}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43149b4f-54db-455f-9d39-6ad2f5c52b94",
   "metadata": {},
   "source": [
    "Now, as the user, we are going to ask the LLM to generate an implementation of the Requests library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0742e7bd-4857-4ed1-a96b-37098d448bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a Python implementation of requesting an API with the Requests library\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1bffe-375f-4a9a-8433-e217eb94aea2",
   "metadata": {},
   "source": [
    "Let's generate the first version of the essay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff984277-733c-4495-b7fd-0669393380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = (\n",
    "    client.chat.completions.create(messages=generation_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")\n",
    "\n",
    "\n",
    "generation_chat_history.append({\"role\": \"assistant\", \"content\": user_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03f208b-2234-4fd1-a02b-f4fff06c01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is a complete Python implementation that demonstrates how to make a simple API request using the `requests` library. The example will cover sending a GET request to a public API and handling the response.\n",
       "\n",
       "```python\n",
       "import requests\n",
       "\n",
       "def fetch_data(api_url):\n",
       "    try:\n",
       "        # Send a GET request to the specified URL\n",
       "        response = requests.get(api_url)\n",
       "        \n",
       "        # Check if the request was successful\n",
       "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx, 5xx)\n",
       "\n",
       "        # Parse the response JSON\n",
       "        data = response.json()  # Assuming the API returns JSON data\n",
       "        return data\n",
       "    \n",
       "    except requests.exceptions.HTTPError as http_err:\n",
       "        print(f\"HTTP error occurred: {http_err}\")  # Print HTTP errors\n",
       "    except requests.exceptions.ConnectionError as conn_err:\n",
       "        print(f\"Connection error occurred: {conn_err}\")  # Print connection errors\n",
       "    except requests.exceptions.Timeout as timeout_err:\n",
       "        print(f\"Timeout error occurred: {timeout_err}\")  # Print timeout errors\n",
       "    except requests.exceptions.RequestException as req_err:\n",
       "        print(f\"An error occurred: {req_err}\")  # Print all other errors\n",
       "\n",
       "# Example usage\n",
       "if __name__ == \"__main__\":\n",
       "    api_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
       "    data = fetch_data(api_url)\n",
       "    \n",
       "    if data:\n",
       "        print(\"Fetched Data:\")\n",
       "        for post in data:\n",
       "            print(f\"ID: {post['id']}, Title: {post['title']}\")\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **Importing the requests library**: The `requests` library is imported, which is needed to make HTTP requests.\n",
       "   \n",
       "2. **Function Definition**: The function `fetch_data(api_url)` is defined to handle the API request.\n",
       "\n",
       "3. **GET Request**: The `requests.get(api_url)` method is used to send a GET request to the specified API URL.\n",
       "\n",
       "4. **Error Handling**: Various exceptions are caught to handle potential errors such as HTTP errors, connection errors, and timeouts.\n",
       "\n",
       "5. **Parsing Response**: The response is parsed as JSON, assuming the API returns JSON formatted data, and the data is returned.\n",
       "\n",
       "6. **Example Usage**: A simple example demonstrates how to use the `fetch_data` function to get data from a sample API (jsonplaceholder), and prints the results.\n",
       "\n",
       "### Note:\n",
       "Make sure the `requests` library is installed in your environment. You can install it using pip if you haven't already:\n",
       "\n",
       "```bash\n",
       "pip install requests\n",
       "```\n",
       "\n",
       "Feel free to modify the example URL or the processing logic as needed for your specific use case!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(user_code, raw=True)\n",
    "# Output below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04ebe5-0573-4520-a529-aff22d486b7d",
   "metadata": {},
   "source": [
    "## Reflection Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020433f1",
   "metadata": {},
   "source": [
    "This is equivalent to asking a follow up question in say ChatGPT and we change the system prompt or what we want it to do along with the output from the previous query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d93c928-d585-48af-a74c-a5b8d84593c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an experienced and talented Pythonista. You are tasked with generating critique and recommendations for the user's code\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26af1a73-4d91-40e8-a9bc-c34d32b2ab82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We add new messages to the list of messages so that the LLM has context and knowledge of what proceeded.\n",
    "\n",
    "# LLM calls are stateless and previous messages are not stored with the LLM. This is an important fact as we do not want to go over the context window for the LLM or incur unwanted costs if applicable.\n",
    "\n",
    "reflection_chat_history.append({\"role\": \"user\", \"content\": user_code})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa994c8-3612-47b0-9571-e21d0d73d896",
   "metadata": {},
   "source": [
    "CRITIQUE TIME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628b75c",
   "metadata": {},
   "source": [
    "Now that we have the context and the request for a critique, we make a request to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fee42f-d47a-41b1-a40d-7208ba76ce98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "critique = (\n",
    "    client.chat.completions.create(messages=reflection_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fef3203-c7f1-407f-8b9b-4e8ae140a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your implementation of making an API request using the `requests` library is straightforward and effectively shows how to handle responses and errors. Here are some critiques and recommendations to enhance the code quality and functionality:\n",
       "\n",
       "### Critiques:\n",
       "\n",
       "1. **Error Handling**: \n",
       "   - While you are catching specific exception types, each catch could be more informative. Instead of just printing, consider logging errors or raising exceptions to allow higher-level handling of the error.\n",
       "\n",
       "2. **Magic Strings**: \n",
       "   - The URL is hard-coded, and while that's fine for a demo, in a more extensive application, you might want to parameterize that or pull it from a configuration file or environment variable.\n",
       "\n",
       "3. **Assumption on Response Type**: \n",
       "   - You are assuming the response is always JSON. APIs may sometimes return an HTML error page or a different format. You could validate the content type before attempting to decode it as JSON.\n",
       "\n",
       "4. **Documentation**: \n",
       "   - While you have provided a nice explanation, consider adding docstrings to your function to improve its readability and provide usage details directly in the code.\n",
       "\n",
       "5. **Return Value**: \n",
       "   - If an error occurs, the function returns `None` implicitly. It's generally better to have an explicit return statement, even in the case of an error, for clarity.\n",
       "\n",
       "### Recommendations:\n",
       "\n",
       "1. **Add Docstrings**: \n",
       "   - Include a docstring for the `fetch_data` function to describe its purpose, parameters, and return value.\n",
       "\n",
       "   ```python\n",
       "   def fetch_data(api_url):\n",
       "       \"\"\"\n",
       "       Fetch data from the provided API URL.\n",
       "\n",
       "       Parameters:\n",
       "           api_url (str): The API endpoint to send a GET request to.\n",
       "\n",
       "       Returns:\n",
       "           dict or None: The response JSON data if the request is successful; None otherwise.\n",
       "       \"\"\"\n",
       "   ```\n",
       "\n",
       "2. **Logging**: \n",
       "   - Instead of using `print` statements for errors, consider using the `logging` module for more robust and configurable error reporting.\n",
       "\n",
       "   ```python\n",
       "   import logging\n",
       "\n",
       "   logging.basicConfig(level=logging.INFO)\n",
       "   logger = logging.getLogger(__name__)\n",
       "   ```\n",
       "\n",
       "3. **Improved Error Handling**: \n",
       "   - After logging the error, consider returning an error response or raising an exception for the calling code to handle how it sees fit.\n",
       "\n",
       "4. **Check Content-Type**: \n",
       "   - Before calling `response.json()`, check if the `Content-Type` header indicates that the response is indeed JSON:\n",
       "\n",
       "   ```python\n",
       "   if 'application/json' in response.headers.get('Content-Type'):\n",
       "       data = response.json()\n",
       "   else:\n",
       "       logger.error(\"Response is not in JSON format.\")\n",
       "       return None\n",
       "   ```\n",
       "\n",
       "5. **Refactor Example Usage**: \n",
       "   - Move the example usage into a separate function to improve code organization.\n",
       "\n",
       "### Revised Code Example:\n",
       "\n",
       "Here’s a revised version incorporating some of these recommendations:\n",
       "\n",
       "```python\n",
       "import requests\n",
       "import logging\n",
       "\n",
       "logging.basicConfig(level=logging.INFO)\n",
       "logger = logging.getLogger(__name__)\n",
       "\n",
       "def fetch_data(api_url):\n",
       "    \"\"\"\n",
       "    Fetch data from the provided API URL.\n",
       "\n",
       "    Parameters:\n",
       "        api_url (str): The API endpoint to send a GET request to.\n",
       "\n",
       "    Returns:\n",
       "        dict or None: The response JSON data if the request is successful; None otherwise.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        response = requests.get(api_url)\n",
       "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
       "\n",
       "        if 'application/json' in response.headers.get('Content-Type'):\n",
       "            data = response.json()\n",
       "            return data\n",
       "        else:\n",
       "            logger.error(\"Response is not in JSON format.\")\n",
       "            return None\n",
       "    \n",
       "    except requests.exceptions.HTTPError as http_err:\n",
       "        logger.error(f\"HTTP error occurred: {http_err}\")\n",
       "    except requests.exceptions.ConnectionError as conn_err:\n",
       "        logger.error(f\"Connection error occurred: {conn_err}\")\n",
       "    except requests.exceptions.Timeout as timeout_err:\n",
       "        logger.error(f\"Timeout error occurred: {timeout_err}\")\n",
       "    except requests.exceptions.RequestException as req_err:\n",
       "        logger.error(f\"An error occurred: {req_err}\")\n",
       "    \n",
       "    return None\n",
       "\n",
       "def main():\n",
       "    api_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
       "    data = fetch_data(api_url)\n",
       "    \n",
       "    if data:\n",
       "        print(\"Fetched Data:\")\n",
       "        for post in data:\n",
       "            print(f\"ID: {post['id']}, Title: {post['title']}\")\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "```\n",
       "\n",
       "This version includes structured logging, better error handling, and enhanced readability through added docstrings and refactored functions. Great job on your initial implementation, and well done on tackling API requests efficiently!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display\n",
    "\n",
    "display_markdown(critique, raw=True)\n",
    "# Critique displayed below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df433b0-d662-4378-895e-6b09dd3201bc",
   "metadata": {},
   "source": [
    "Add CRITIQUE to chat...\n",
    "\n",
    "Notice how we are appending previous responses so that the next SYSTEM MESSAGE has history or context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a85bb3-cf6a-4576-8caf-cd41e602a1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_chat_history.append({\"role\": \"user\", \"content\": critique})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1aefa-8454-41ab-af40-2675f340a577",
   "metadata": {},
   "source": [
    "Response to CRITIQUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d845cf-51c3-4cfd-b6a7-1b970413f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essay = (\n",
    "    client.chat.completions.create(messages=generation_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef14eaa8-f501-4efc-997f-8564ec8dccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thank you for your constructive feedback! Here’s the revised implementation incorporating your critiques and recommendations for optimizing the API request with the `requests` library:\n",
       "\n",
       "```python\n",
       "import requests\n",
       "import logging\n",
       "\n",
       "# Configure logging\n",
       "logging.basicConfig(level=logging.INFO)\n",
       "logger = logging.getLogger(__name__)\n",
       "\n",
       "def fetch_data(api_url):\n",
       "    \"\"\"\n",
       "    Fetch data from the provided API URL.\n",
       "\n",
       "    Parameters:\n",
       "        api_url (str): The API endpoint to send a GET request to.\n",
       "\n",
       "    Returns:\n",
       "        dict or None: The response JSON data if the request is successful; None otherwise.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Send a GET request to the specified URL\n",
       "        response = requests.get(api_url)\n",
       "        \n",
       "        # Check if the request was successful\n",
       "        response.raise_for_status()\n",
       "\n",
       "        # Check if the response is in JSON format\n",
       "        if 'application/json' in response.headers.get('Content-Type', ''):\n",
       "            return response.json()\n",
       "        else:\n",
       "            logger.error(\"Response is not in JSON format.\")\n",
       "            return None\n",
       "            \n",
       "    except requests.exceptions.HTTPError as http_err:\n",
       "        logger.error(f\"HTTP error occurred: {http_err}\")\n",
       "    except requests.exceptions.ConnectionError as conn_err:\n",
       "        logger.error(f\"Connection error occurred: {conn_err}\")\n",
       "    except requests.exceptions.Timeout as timeout_err:\n",
       "        logger.error(f\"Timeout error occurred: {timeout_err}\")\n",
       "    except requests.exceptions.RequestException as req_err:\n",
       "        logger.error(f\"An error occurred: {req_err}\")\n",
       "    \n",
       "    return None\n",
       "\n",
       "def main():\n",
       "    # Example API URL\n",
       "    api_url = \"https://jsonplaceholder.typicode.com/posts\"\n",
       "    data = fetch_data(api_url)\n",
       "    \n",
       "    if data:\n",
       "        print(\"Fetched Data:\")\n",
       "        for post in data:\n",
       "            print(f\"ID: {post['id']}, Title: {post['title']}\")\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "```\n",
       "\n",
       "### Key Improvements Made:\n",
       "- **Docstrings**: Added a docstring to `fetch_data` to clearly describe what the function does, its parameters, and its return value.\n",
       "- **Logging**: Replaced `print` statements with logging for better error tracking and configurability.\n",
       "- **Content-Type Check**: Added a check to ensure that the response is JSON before trying to parse it.\n",
       "- **Explicit Return on Error**: The function now explicitly returns `None` in the case of caught exceptions, providing clarity in error handling.\n",
       "\n",
       "These changes enhance the code quality, maintainability, and clarity, ensuring it is better suited for production-level implementations. Thank you for the opportunity to refine this code! If you have any further suggestions or need additional features, feel free to ask!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diaply user response to CRITIQUE\n",
    "display_markdown(essay, raw=True)\n",
    "# Response to critique displayed below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75883af2-f31d-4c24-b1ff-315a0711f9fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### We can of course make this a Class...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
