{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514b9aab",
   "metadata": {},
   "source": [
    "<img src=\"./ESSENCE.png\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4d7b7-40bf-43b9-a626-2a11d5529ac8",
   "metadata": {},
   "source": [
    "### Reflection pattern\n",
    "\n",
    "## input -> function(input) -> output -> function(output) -> output2\n",
    "\n",
    "<img src=\"./INPUT_OUTPUT.png\" width=700px>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e847f",
   "metadata": {},
   "source": [
    "## Agent One is a code expert. Agent Two is an expert code reviewer.\n",
    "\n",
    "We generate a response with our first query using a system prompt to create code.\n",
    "\n",
    "We then pass the output into another function that acts as a reviewer to produce the next version of the code.\n",
    "\n",
    "This can be repeated until we reach certain criteria or MAX_ITERATIONS, whichever comes first.\n",
    "\n",
    "Each query is as if it was the first query with more information contained within it as each request is stateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96731d2f-a079-4e41-9756-220f02d4ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9729eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed931fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-TVyeca...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:14]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644a635-e035-44e2-8c25-cee0f2b56556",
   "metadata": {},
   "source": [
    "We will start the **\"generation\"** chat history with the system prompt, as we said before. In this case, let the LLM act like a Python\n",
    "programmer eager to receive feedback / critique by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12467256-c741-495a-9923-439c1fcf270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "You are a Python programmer tasked with generating high quality Python code. Your task is to Generate the best content possible for the user's request. If the user requests critique, respond with a revised version of your previous attempt.\n",
    "\"\"\"\n",
    "\n",
    "generation_chat_history = [{\"role\": \"system\", \"content\": content}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43149b4f-54db-455f-9d39-6ad2f5c52b94",
   "metadata": {},
   "source": [
    "Now, as the user, we are going to ask the LLM to generate an implementation of the Requests library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0742e7bd-4857-4ed1-a96b-37098d448bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chat_history.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate a Python implementation of requesting an API with the Requests library\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1bffe-375f-4a9a-8433-e217eb94aea2",
   "metadata": {},
   "source": [
    "Let's generate the first version of the essay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff984277-733c-4495-b7fd-0669393380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = (\n",
    "    client.chat.completions.create(messages=generation_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")\n",
    "\n",
    "\n",
    "generation_chat_history.append({\"role\": \"assistant\", \"content\": user_code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03f208b-2234-4fd1-a02b-f4fff06c01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a simple Python implementation that demonstrates how to request data from an API using the Requests library. This example includes error handling and JSON response parsing.\n",
       "\n",
       "```python\n",
       "import requests\n",
       "\n",
       "def fetch_data_from_api(url):\n",
       "    try:\n",
       "        # Send a GET request to the specified URL\n",
       "        response = requests.get(url)\n",
       "        \n",
       "        # Raise an exception for HTTP error responses\n",
       "        response.raise_for_status()\n",
       "\n",
       "        # Parse JSON response if content is in JSON format\n",
       "        if response.headers['Content-Type'] == 'application/json':\n",
       "            data = response.json()\n",
       "            return data\n",
       "        \n",
       "        # Return response text if not JSON\n",
       "        return response.text\n",
       "        \n",
       "    except requests.exceptions.RequestException as e:\n",
       "        print(f\"An error occurred: {e}\")\n",
       "        return None\n",
       "\n",
       "# Example usage\n",
       "if __name__ == \"__main__\":\n",
       "    api_url = \"https://api.example.com/data\"  # Replace with a valid API endpoint\n",
       "    result = fetch_data_from_api(api_url)\n",
       "    \n",
       "    if result is not None:\n",
       "        print(\"Retrieved data:\", result)\n",
       "    else:\n",
       "        print(\"Failed to retrieve data.\")\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **Importing Requests Library**: The `requests` module is imported to handle HTTP requests.\n",
       "2. **Function `fetch_data_from_api`**: This function takes a URL as an argument:\n",
       "   - It sends a GET request to that URL.\n",
       "   - It raises exceptions for any HTTP errors (like 404 or 500).\n",
       "   - It checks if the response is in JSON format and parses it accordingly.\n",
       "   - If the response isn't JSON, it returns the response text.\n",
       "3. **Error Handling**: The `try-except` block captures any exceptions that may arise during the request, making it more robust.\n",
       "4. **Example Usage**: The script includes an example of how to call the function with a sample API URL.\n",
       "\n",
       "Make sure to install the Requests library if you haven't already by using:\n",
       "```bash\n",
       "pip install requests\n",
       "```\n",
       "\n",
       "Feel free to replace the example URL with any valid API endpoint to test the code!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(user_code, raw=True)\n",
    "# Output below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04ebe5-0573-4520-a529-aff22d486b7d",
   "metadata": {},
   "source": [
    "## Reflection Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020433f1",
   "metadata": {},
   "source": [
    "This is equivalent to asking a follow up question in say ChatGPT and we change the system prompt or what we want it to do along with the output from the previous query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d93c928-d585-48af-a74c-a5b8d84593c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reflection_chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an experienced and talented Pythonista. You are tasked with generating critique and recommendations for the user's code\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26af1a73-4d91-40e8-a9bc-c34d32b2ab82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We add new messages to the list of messages so that the LLM has context and knowledge of what proceeded.\n",
    "\n",
    "# LLM calls are stateless and previous messages are not stored with the LLM. This is an important fact as we do not want to go over the context window for the LLM or incur unwanted costs if applicable.\n",
    "\n",
    "reflection_chat_history.append({\"role\": \"user\", \"content\": user_code})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa994c8-3612-47b0-9571-e21d0d73d896",
   "metadata": {},
   "source": [
    "CRITIQUE TIME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628b75c",
   "metadata": {},
   "source": [
    "Now that we have the context and the request for a critique, we make a request to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fee42f-d47a-41b1-a40d-7208ba76ce98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "critique = (\n",
    "    client.chat.completions.create(messages=reflection_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fef3203-c7f1-407f-8b9b-4e8ae140a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your implementation for fetching data from an API using the `requests` library in Python is quite solid. It effectively demonstrates essential practices, such as error handling and response parsing. Below are some critiques and recommendations for potential improvements:\n",
       "\n",
       "### Critiques:\n",
       "\n",
       "1. **Content-Type Check**:\n",
       "   - You're currently checking the `Content-Type` header directly from the response. While this often works, it's best practice to use the `response.json()` method within a try-except block to handle cases where the response might not be in JSON format, which will automatically raise a `JSONDecodeError`.\n",
       "\n",
       "2. **Handling Non-200 Status Codes**:\n",
       "   - The `raise_for_status()` method effectively handles non-200 status codes. However, you could provide additional context in the exception message for better debugging.\n",
       "\n",
       "3. **Return Value Consistency**:\n",
       "   - The function may return either a JSON object (if the content is JSON) or a string (if it's not JSON). This could potentially lead to confusion since the return type is not consistent. Documenting this in your function's docstring may help users understand the expected behavior.\n",
       "\n",
       "4. **Retries for API Requests**:\n",
       "   - To handle transient issues, consider adding a retry mechanism using `requests` built-in support or the `tenacity` library. This can improve robustness further, particularly in scenarios where network issues are common.\n",
       "\n",
       "5. **Logging Instead of Printing**:\n",
       "   - Instead of using print statements for errors, consider using the `logging` library, which provides more flexibility and control over how messages are logged.\n",
       "\n",
       "6. **Docstring**:\n",
       "   - Adding a docstring to explain the function’s purpose, parameters, return, and any exceptions that may be raised will enhance code readability and maintainability.\n",
       "\n",
       "### Recommendations:\n",
       "\n",
       "Here’s an enhanced version of your code based on the critiques and recommendations above:\n",
       "\n",
       "```python\n",
       "import requests\n",
       "import logging\n",
       "\n",
       "# Set up logging configuration\n",
       "logging.basicConfig(level=logging.INFO)\n",
       "\n",
       "def fetch_data_from_api(url):\n",
       "    \"\"\"\n",
       "    Fetch data from the specified API URL.\n",
       "    \n",
       "    Args:\n",
       "        url (str): The URL of the API endpoint.\n",
       "        \n",
       "    Returns:\n",
       "        dict or str: Parsed JSON data if the response is JSON, \n",
       "                     else the raw response text. None if an error occurs.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Send a GET request to the specified URL\n",
       "        response = requests.get(url)\n",
       "        \n",
       "        # Raise an exception for HTTP error responses\n",
       "        response.raise_for_status() \n",
       "\n",
       "        # Attempt to parse JSON response\n",
       "        try:\n",
       "            return response.json()\n",
       "        except ValueError:\n",
       "            logging.warning(f\"Response content is not JSON. Returning text instead.\")\n",
       "            return response.text\n",
       "        \n",
       "    except requests.exceptions.RequestException as e:\n",
       "        logging.error(f\"An error occurred: {e}\")\n",
       "        return None\n",
       "\n",
       "# Example usage\n",
       "if __name__ == \"__main__\":\n",
       "    api_url = \"https://api.example.com/data\"  # Replace with a valid API endpoint\n",
       "    result = fetch_data_from_api(api_url)\n",
       "    \n",
       "    if result is not None:\n",
       "        logging.info(\"Retrieved data: %s\", result)\n",
       "    else:\n",
       "        logging.error(\"Failed to retrieve data.\")\n",
       "```\n",
       "\n",
       "### Key Improvements:\n",
       "- **Error Logging**: This code utilizes the `logging` library for clearer and more adjustable error handling.\n",
       "- **Improved JSON Handling**: It attempts JSON parsing separately and catches any errors, allowing for better handling if the response isn't JSON.\n",
       "- **Docstring Addition**: Gives clarity on the function's parameters and return types, improving maintainability.\n",
       "\n",
       "These enhancements should create a more robust and clear implementation for users interacting with your API-fetching code."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display\n",
    "\n",
    "display_markdown(critique, raw=True)\n",
    "# Critique displayed below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df433b0-d662-4378-895e-6b09dd3201bc",
   "metadata": {},
   "source": [
    "Add CRITIQUE to chat...\n",
    "\n",
    "Notice how we are appending previous responses so that the next SYSTEM MESSAGE has history or context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a85bb3-cf6a-4576-8caf-cd41e602a1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_chat_history.append({\"role\": \"user\", \"content\": critique})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1aefa-8454-41ab-af40-2675f340a577",
   "metadata": {},
   "source": [
    "Response to CRITIQUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d845cf-51c3-4cfd-b6a7-1b970413f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "essay = (\n",
    "    client.chat.completions.create(messages=generation_chat_history, model=MODEL)\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef14eaa8-f501-4efc-997f-8564ec8dccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's the revised version of the API fetching implementation based on your critiques and suggestions:\n",
       "\n",
       "```python\n",
       "import requests\n",
       "import logging\n",
       "\n",
       "# Set up logging configuration\n",
       "logging.basicConfig(level=logging.INFO)\n",
       "\n",
       "def fetch_data_from_api(url):\n",
       "    \"\"\"\n",
       "    Fetch data from the specified API URL.\n",
       "\n",
       "    Args:\n",
       "        url (str): The URL of the API endpoint.\n",
       "\n",
       "    Returns:\n",
       "        dict or str: Parsed JSON data if the response is JSON,\n",
       "                     else the raw response text. Returns None if an error occurs.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Send a GET request to the specified URL\n",
       "        response = requests.get(url)\n",
       "        \n",
       "        # Raise an exception for HTTP error responses\n",
       "        response.raise_for_status()\n",
       "\n",
       "        # Attempt to parse JSON response\n",
       "        try:\n",
       "            return response.json()\n",
       "        except ValueError:\n",
       "            logging.warning(\"Response content is not JSON. Returning text instead.\")\n",
       "            return response.text\n",
       "        \n",
       "    except requests.exceptions.RequestException as e:\n",
       "        logging.error(\"An error occurred while fetching data: %s\", e)\n",
       "        return None\n",
       "\n",
       "# Example usage\n",
       "if __name__ == \"__main__\":\n",
       "    api_url = \"https://api.example.com/data\"  # Replace with a valid API endpoint\n",
       "    result = fetch_data_from_api(api_url)\n",
       "    \n",
       "    if result is not None:\n",
       "        logging.info(\"Retrieved data: %s\", result)\n",
       "    else:\n",
       "        logging.error(\"Failed to retrieve data.\")\n",
       "```\n",
       "\n",
       "### Key Improvements:\n",
       "1. **Error Handling**: The function uses a separate `try-except` block around the JSON parsing to catch `ValueError`, which provides a clear distinction when dealing with non-JSON responses.\n",
       "2. **Logging**: `logging` has been used instead of `print`, enabling better control over the output and the ability to set different logging levels.\n",
       "3. **Consistent Return Documentation**: The docstring now includes a clear explanation of what the function returns based on the API response.\n",
       "\n",
       "This version of the code is more robust and user-friendly, improving the maintainability and clarity for future modifications or inquiries. Thank you for your feedback!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diaply user response to CRITIQUE\n",
    "display_markdown(essay, raw=True)\n",
    "# Response to critique displayed below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75883af2-f31d-4c24-b1ff-315a0711f9fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### We can of course make this a Class...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
