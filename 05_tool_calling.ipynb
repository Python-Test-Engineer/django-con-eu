{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4e0ba5",
   "metadata": {},
   "source": [
    "<img src=\"./images/05-tool.png\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2d04d",
   "metadata": {},
   "source": [
    "We have seen that the LLM needs a complete picture of what it needs to do.\n",
    "\n",
    "We have been adding extra data to the prompt and then running a new query.\n",
    "\n",
    "Sometimes we need extra information that we can't provide at the start of the prompt. We can use a Tool to get this information and the LLM will be able to select the correct tool and run it.\n",
    "\n",
    "We saw in ROUTER how we can get the LLM to select the most appropriate report or in this case tool.\n",
    "\n",
    "When we say run it, the LLM passes 'us' information on the function that needs to be run and the arguments to be used. \n",
    "\n",
    "The LLM can also extract data from the prompt.\n",
    "\n",
    "We then run the function and send back the output to the LLM by appending to the list of messages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dfced",
   "metadata": {},
   "source": [
    "In the cases where where an Agent calls a tool, the tool is called on our box.\n",
    "\n",
    "Where are the functions run? From the OpenAI website, we can see at the arrow that tools are executed on our 'box'.\n",
    "\n",
    "<img style=\"width:1100px;\" src=\"./images/where-tools-are-executed.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84142088",
   "metadata": {},
   "source": [
    "Like routing, we can also ask the LLM to select the most appropriate tool to use.\n",
    "\n",
    "In this example, we see how we can do Tool Selection and Data Extraction. The Agent determines what it will do next and also extracts data from the\n",
    "LLM response as arguments for the next step. (In 20_planning we will see Tool Calling that use defined functions in our code but for this example,\n",
    "we will do this manually).\n",
    "\n",
    "In essence, the LLM decides on the tool/function it wants to use and send back the function name and arguments for us to run on our own box,\n",
    "get the result and then add this to the messages in the next LLM request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-TVyeca...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:14]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd922b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original propmt\n",
    "system_message = \"\"\"\n",
    "You are an assistant that is very good at determining what tool to use to solve queries.\n",
    "\"\"\"\n",
    "\n",
    "ai_programming = \"\"\"\n",
    "\n",
    "# TOOLS\n",
    "\n",
    "You have two tools:\n",
    "\n",
    "1. A calculator tool that can perform basic arithmetic operations, such as addition, subtraction, multiplication, and division. If this tool is used then respond in JSON FORMAT.\n",
    "\n",
    "## Example JSON format:\n",
    "\n",
    "{\"tool\": \"calculator\", \"next\": \"do_calculation\", \"arguments\": {\"num1\": 5, \"num2\": 5, \"operation\": \"addition\"}} \n",
    "\n",
    "2. A jokes tool that can provide a light-hearted joke for the audience reqested. If this tool is used then respond in JSON FORMAT.\n",
    "\n",
    "## Example JSON format:\n",
    "\n",
    "{\"tool\": \"joke\", \"next\": \"do_joke\", \"audience\": \"Pythonistas\" }} \n",
    "\n",
    "Thank you for your being accurate and complete with this query.\n",
    "\"\"\"\n",
    "system_message += ai_programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fa6d2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tool\": \"calculator\", \"next\": \"do_calculation\", \"arguments\": {\"num1\": 102, \"num2\": 3, \"operation\": \"addition\"}}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What is 102 plus 3?\"\n",
    "# user_prompt = \"Tell me a joke when I am doing stand up at a Python Conference\"\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "response = client.chat.completions.create(model=MODEL, messages=prompts)\n",
    "print(response.choices[0].message.content)\n",
    "output = response.choices[0].message.content.replace(\"\\n\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46d61af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tool\": \"calculator\", \"next\": \"do_calculation\", \"arguments\": {\"num1\": 102, \"num2\": 3, \"operation\": \"addition\"}}\n"
     ]
    }
   ],
   "source": [
    "# As specified in the AI Programming section of the prompt, we get back a JSON response/dictionary with what\n",
    "# the next step should be.\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d890bd",
   "metadata": {},
   "source": [
    "Having got the function and arguments, we extract these from the response and run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fe3437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool': 'calculator', 'next': 'do_calculation', 'arguments': {'num1': 102, 'num2': 3, 'operation': 'addition'}}\n"
     ]
    }
   ],
   "source": [
    "json_output = output.strip()\n",
    "json_output = json.loads(json_output)\n",
    "print(json_output)\n",
    "# use do_next as 'next' is a reserved word\n",
    "do_next = json_output[\"next\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a24fe",
   "metadata": {},
   "source": [
    "Now we use our day to day Python to run some code based on the next step, _very much like calling a Weather API and then writing code based on the result._\n",
    "\n",
    "There are other ways we might code this but this will suffice for demonstration purposes.\n",
    "\n",
    "In this demo, we use the calculator tool or joke tool to give a response. The tool is some code rather than a defined functuion, we will see this in the PLANNING demo `20_planning`, we will use the tools to call functions in our code which we then feedback to the LLM to carry out the next stage of the plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34cfd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could be encapsulated into a function\n",
    "if do_next == \"do_joke\":\n",
    "    get_random_joke_internet = requests.get(\n",
    "        \"https://official-joke-api.appspot.com/random_joke\"\n",
    "    )\n",
    "    print(get_random_joke_internet.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "473647c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 addition 3 = 105\n"
     ]
    }
   ],
   "source": [
    "# this could be encapsulated into a function\n",
    "# the main point is we have extracted the tool and data from the response\n",
    "if do_next == \"do_calculation\":\n",
    "    tool = json_output[\"tool\"]\n",
    "    num1 = json_output[\"arguments\"][\"num1\"]\n",
    "    num2 = json_output[\"arguments\"][\"num2\"]\n",
    "    operation = json_output[\"arguments\"][\"operation\"]\n",
    "    if operation == \"addition\":\n",
    "        answer = num1 + num2\n",
    "    elif operation == \"subtraction\":\n",
    "        answer = num1 - num2\n",
    "    elif operation == \"multiplication\":\n",
    "        answer = num1 * num2\n",
    "    elif operation == \"division\":\n",
    "        answer = num1 / num2\n",
    "    print(f\"{num1} {operation} {num2} = {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003e17b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
