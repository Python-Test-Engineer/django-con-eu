{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ API Key exists and begins gsk_11hFN1EMfj...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import instructor\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from groq import Groq\n",
    "from pprint import pprint\n",
    "\n",
    "model = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# Load the Groq API key from .env file\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "print(f\"GROQ API Key exists and begins {GROQ_API_KEY[:14]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.UserInfo'>\n",
      "Name: John Doe\n",
      "Age: 35\n",
      "Email: johndoe@example.com\n"
     ]
    }
   ],
   "source": [
    "# Describe the desired output schema using pydantic models\n",
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "\n",
    "\n",
    "# The text to extract data from\n",
    "text = \"\"\"\n",
    "John Doe, a 35-year-old software engineer from New York, has been working with large language models for several years.\n",
    "His email address is johndoe@example.com.\n",
    "\"\"\"\n",
    "\n",
    "# Patch Groq() with instructor, this is where the magic happens!\n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)\n",
    "\n",
    "# Call the API\n",
    "user_info = client.chat.completions.create(\n",
    "    model=model,\n",
    "    response_model=UserInfo,  # Specify the response model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your job is to extract user information from the given text.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ],\n",
    "    temperature=0.65,\n",
    ")\n",
    "print(type(user_info))\n",
    "print(f\"Name: {user_info.name}\")\n",
    "print(f\"Age: {user_info.age}\")\n",
    "print(f\"Email: {user_info.email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we've defined a simple pydantic model `UserInfo` that specifies a person's name (as a string), age (as an integer), and email (as a string). The `instructor` library ensures that the Groq model's output adheres to this schema. The great thing here is that the `instructor` library ensures the response is valid according to the schema you provided. This eliminates the need for manual validation and reduces the likelihood of errors creeping into your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A More Serious Use Case: Generating Synthetic Data\n",
    "\n",
    "Imagine you are designing a weather agent capable of calling functions (tools). This agent is given a `get_weather_info` tool to retrieve the latest weather information about a location. The JSON schema for this tool is provided here:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"get_weather_info\",\n",
    "    \"description\": \"Get the weather information for any location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The location for which we want to get the weather information (e.g., New York)\" \n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Our goal is to create a structured dataset of realistic examples that simulate how a user might request weather information in various scenarios. We want to use a large language model (LLM) to generate these examples for us and use them as an evaluation set to test our agent's capabilities. Without such an evaluation, we lack a way to understand the effects of our prompt adjustments. These examples will not only help us evaluate the agent's ability to use the `get_weather_info` tool correctly but also make it easy to detect if any prompt changes have negative effects.\n",
    "\n",
    "Now, let's use the `instructor` library with Groq to generate synthetic examples for our weather agent.\n",
    "\n",
    "### Defining the Task and Schema\n",
    "\n",
    "To generate these examples, we need to write a prompt that instructs the model to create scenarios where an agent would use the `get_weather_info` tool. We can use the following system prompt for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I am designing a weather agent. This agent can talk to the user and also fetch latest weather information.\n",
    "It has access to the `get_weather_info` tool with the following JSON schema:\n",
    "{json_schema}\n",
    "\n",
    "I want you to write some examples for `get_weather_info` and see if this functionality works correctly and can handle all the cases. \n",
    "Now given the information so far and the JSON schema of the provided tool, write {num} examples.\n",
    "Make sure each example is varied enough to cover common ways of requesting for this functionality.\n",
    "Make sure you fill the function parameters with the correct types when generating the output examples. \n",
    "Make sure your output is valid JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to specify the structure of the output. For this task, I want the output to include the example text, the tool to call, and also the parameters of the tool. Something like the following:\n",
    "```json\n",
    "{\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"input_text\": \"Get the weather information for San Francisco.\",\n",
    "            \"tool_name\": \"get_weather_info\",\n",
    "            \"tool_parameters\": \"{\\\"location\\\":\\\"San Francisco\\\"}\"\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "We can easily translate this structure into a Pydantic model like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(BaseModel):\n",
    "    input_text: str = Field(description=\"The example text\")\n",
    "    tool_name: str = Field(description=\"The tool name to call for this example\")\n",
    "    tool_parameters: str = Field(\n",
    "        description=\"An object containing the key-value pairs for the parameters of this tool as a JSON serializbale STRING, make sure it is valid JSON and parameter values are of the correct type according to the tool schema\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ResponseModel(BaseModel):\n",
    "    examples: list[Example]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Examples\n",
    "Now let's call the Groq API with our custom prompt and ask it to generate 5 examples for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ResponseModel'>\n",
      "[Example(input_text='What is the weather like in New York?', tool_name='get_weather_info', tool_parameters='{\"location\": \"New York\"}'),\n",
      " Example(input_text='Get me the weather information for London', tool_name='get_weather_info', tool_parameters='{\"location\": \"London\"}'),\n",
      " Example(input_text='I want to know the weather in Paris', tool_name='get_weather_info', tool_parameters='{\"location\": \"Paris\"}'),\n",
      " Example(input_text=\"What's the weather like in Sydney today?\", tool_name='get_weather_info', tool_parameters='{\"location\": \"Sydney\"}'),\n",
      " Example(input_text='Can you tell me the weather forecast for Tokyo?', tool_name='get_weather_info', tool_parameters='{\"location\": \"Tokyo\"}')]\n"
     ]
    }
   ],
   "source": [
    "# The schema for get_weather_info tool\n",
    "tool_schema = {\n",
    "    \"name\": \"get_weather_info\",\n",
    "    \"description\": \"Get the weather information for any location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The location for which we want to get the weather information (e.g. New York)\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Patch Groq() with instructor, this is where the magic happens!\n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON)\n",
    "\n",
    "# Call the API with our custom prompt and ResponseModel\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    response_model=ResponseModel,  # Specify the response model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt.format(\n",
    "                json_schema=tool_schema, num=5\n",
    "            ),  # Pass the tool schema and number of examples to the prompt\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.65,\n",
    "    max_tokens=8000,\n",
    ")\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
